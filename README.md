# Privet project
to operate this code get files out from input files then run the delete_dublicate.py code don't forget to install pandas 
then the file in input phase 2 should appear then then run code called compare_time.py to get the final result located in the file output
# What this project was for
As a freelancer data analyst for an employer at a privet KSA Company. 
I was responsible for analyzing a large corrupted dataset of more than 30 pharmacies 
with more than 105 thousand rows I removed duplication using Python and Pandas
under sort of algorithm depend on fields in the column to shrink it to 90 thousand then 
compare it to another sheet with the difference in columns to get the different rows 
I reduced the effort of the employer from 105 thousand row checks to 5 thousand 
